{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightweight Face Detector TF Implementation\n",
    "\n",
    "Based almost entirely off the paper: \"A lightweight face detector by integrating the convolutional neural network with the image pyramid\"\n",
    "\n",
    "Github link: https://github.com/JiapengLuo/lightweight_face_detector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# saved_model_path = \"/Users/johngearig/Downloads/lightweight_face_detector-master/checkpoints/fast_mode_enable_hflip\"\n",
    "# im_path = '/Users/johngearig/Downloads/lightweight_face_detector-master/demo1.jpg'\n",
    "# out_path = '/Users/johngearig/Downloads/lightweight_face_detector-master/demo1_detected.jpg'\n",
    "\n",
    "saved_model_path = \"/Users/james/Downloads/lightweight_face_detector-master/lightweight_face_detector-master/checkpoints/fast_mode_enable_hflip\"\n",
    "im_path = \"Images/0--Parade/0_Parade_marchingband_1_5.jpg\"\n",
    "out_path = \"Images/0--Parade/0_Parade_marchingband_1_5_Detected.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: This will not run on any recent tensorflow release since it relies heavily on tf.Session() which was discontinued in tf.__version__ 2.0.\n",
    "\n",
    "The Pillow import is only for viewing images and could be swapped for another image library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(img, boxes, color='green', width=2):\n",
    "    '''\n",
    "    draw the boxes in the img\n",
    "    :param img: Pillow Image or numpy\n",
    "    :param boxes: boxes, [[ymax, xmax, ymin, xmin]...]\n",
    "    :param color: color\n",
    "    :return: Image drawed boxes\n",
    "    '''\n",
    "    if isinstance(img, np.ndarray):\n",
    "        img = Image.fromarray(img.astype(np.uint8), mode='RGB')\n",
    "    elif not isinstance(img, Image.Image):\n",
    "        raise ValueError(\"image must be a Image or ndarray.\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for box in boxes:\n",
    "        draw.rectangle([box[1], box[0], box[3], box[2]], outline=color, width=width)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/james/Downloads/lightweight_face_detector-master/lightweight_face_detector-master/checkpoints/fast_mode_enable_hflip\\variables\\variables\n",
      "1.815000295639038\n",
      "boxes\n",
      "[[179.1147   495.18933  227.00143  533.06964 ]\n",
      " [224.51584  222.12839  264.8469   259.00592 ]\n",
      " [166.6549   920.58356  208.31926  958.56036 ]\n",
      " [190.55524  717.49146  223.84572  748.8699  ]\n",
      " [154.6563   783.63904  192.61717  814.4587  ]\n",
      " [207.72005   25.534302 237.98586   52.600792]\n",
      " [183.32559  963.8858   209.97064  985.2466  ]\n",
      " [190.24266  597.7865   218.52728  621.3916  ]\n",
      " [205.95287  313.8265   265.47736  366.62473 ]\n",
      " [ 98.289986 430.97546  127.819695 453.5537  ]\n",
      " [ 49.071083 744.5245    80.832855 773.2537  ]]\n",
      "scores\n",
      "[0.9999939  0.9999304  0.99912494 0.99272    0.971548   0.8964634\n",
      " 0.84496075 0.78985494 0.7587339  0.62578005 0.5680562 ]\n"
     ]
    }
   ],
   "source": [
    "def run():\n",
    "    sess = tf.compat.v1.Session()\n",
    "    tf.saved_model.load(sess, ['serve'], saved_model_path )\n",
    "    \n",
    "    inp = sess.graph.get_tensor_by_name('input_images:0')\n",
    "    boxes_tensor = sess.graph.get_tensor_by_name('boxes:0')\n",
    "    scores_tensor = sess.graph.get_tensor_by_name('scores:0')\n",
    "\n",
    "    im = Image.open(im_path)\n",
    "    im = np.array(im).astype(np.float32)\n",
    "    \n",
    "    start = time.time()\n",
    "    boxes, scores = sess.run([boxes_tensor,scores_tensor], feed_dict={inp: np.expand_dims(im, axis=0)})\n",
    "    end = time.time()\n",
    "    print(end - start)\n",
    "    \n",
    "    \"\"\"print(boxes.shape)\n",
    "    print(boxes.dtype)\n",
    "    print(scores.shape)\n",
    "    scores = np.reshape(scores, (1,200,1))\n",
    "    \n",
    "    universal = np.concatenate((boxes, scores))\n",
    "    print(universal.shape)\"\"\"\n",
    "    \n",
    "    boxes = boxes[0]\n",
    "    scores = scores[0]\n",
    "    mask = scores>0.5\n",
    "    boxes = boxes[mask]\n",
    "    scores = scores[mask]\n",
    "    print('boxes')\n",
    "    print(boxes)\n",
    "    print('scores')\n",
    "    print(scores)\n",
    "    out_im = draw_boxes(im, boxes)\n",
    "    out_im.save(out_path)\n",
    "\n",
    "if __name__ =='__main__':\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(out_path)  \n",
    "im.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "All code below is trying to figure out the correct reshapes needed to make compatible with other codebase\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 4)\n",
      "float64\n",
      "(1, 5)\n",
      "(1, 5, 1)\n",
      "(1, 5, 5)\n",
      "(1, 1, 5, 5)\n",
      "(1, 1, 5, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[0.        , 0.        , 0.82136708, 0.01504648, 0.27813835,\n",
       "          0.62545221, 0.85360546],\n",
       "         [0.        , 0.        , 0.4234704 , 0.61438293, 0.79574112,\n",
       "          0.77141319, 0.68048199],\n",
       "         [0.        , 0.        , 0.31205906, 0.7244687 , 0.93054864,\n",
       "          0.98969232, 0.2193512 ],\n",
       "         [0.        , 0.        , 0.41939425, 0.65155539, 0.91466768,\n",
       "          0.65834126, 0.16409021],\n",
       "         [0.        , 0.        , 0.30136986, 0.48713553, 0.39105764,\n",
       "          0.25110057, 0.45292768]]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x = 5\n",
    "\n",
    "boxes = np.random.rand(1,x,4)\n",
    "scores = np.random.rand(1,x)\n",
    "\n",
    "print(boxes.shape)\n",
    "print(boxes.dtype)\n",
    "print(scores.shape)\n",
    "\n",
    "scores = np.reshape(scores, (1,x,1))\n",
    "print(scores.shape)\n",
    "universal = np.concatenate((boxes, scores),2)\n",
    "print(universal.shape)\n",
    "\n",
    "universal = np.reshape(universal, (1,1,x,5))\n",
    "empty = np.zeros((1,1,x,2))\n",
    "print(universal.shape)\n",
    "\n",
    "universal = np.concatenate((empty, universal),3)\n",
    "print(universal.shape)\n",
    "\n",
    "universal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
